{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Makemore lesson 2\n",
    "\n",
    "The task is to implement this network:\n",
    "\n",
    "![MLP](images/MLP.png)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cafbeb3098f5b5e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline "
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:49:59.440259618Z",
     "start_time": "2024-02-26T10:49:59.398237243Z"
    }
   },
   "id": "initial_id",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8 ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:55:28.486965214Z",
     "start_time": "2024-02-26T09:55:28.484397123Z"
    }
   },
   "id": "65e2c0f6fbf7a808"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "32033"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:55:28.488278677Z",
     "start_time": "2024-02-26T09:55:28.485237916Z"
    }
   },
   "id": "37793f2830a998a3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "# string to integer\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "# integer to string\n",
    "itos = {i:s for s,i in stoi.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:55:28.488757977Z",
     "start_time": "2024-02-26T09:55:28.485485937Z"
    }
   },
   "id": "83ff5a63dd12a2df"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "26"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:37:40.126074572Z",
     "start_time": "2024-02-26T10:37:40.122350779Z"
    }
   },
   "id": "78ff9805eb23bb9f",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "# context length: how many characters we take to predict the next one\n",
    "block_size = 3\n",
    "\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    \n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(\"\".join(itos[i] for i in context), \"--->\", itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:59:57.568122561Z",
     "start_time": "2024-02-26T09:59:57.527452513Z"
    }
   },
   "id": "ba428cfe3791c926"
  },
  {
   "cell_type": "markdown",
   "source": [
    "X is now a vector of integers representing different words that have occurred together in the dataset. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "510ae2ee14f1b59e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([32, 3]), torch.Size([32]))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:00:01.429247251Z",
     "start_time": "2024-02-26T10:00:01.423158519Z"
    }
   },
   "id": "346f2b8760f07468"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create a vector C with rows equal to the number of characters in the dataset (27) and columns the size of the embeddings (2). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cbd3a0e731105b5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([27, 2])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn(27, 2)\n",
    "C.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:59:20.466014108Z",
     "start_time": "2024-02-26T09:59:20.459741685Z"
    }
   },
   "id": "e4b5c44005ab25b8",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Embed simultaneously all integers of X. \n",
    "\n",
    "We can see that the result is a vector of of the same shape as X, but with a new dimension of 2, which is the embedding for each word. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3693ab99b8d482dc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 3, 2])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:47:11.269137976Z",
     "start_time": "2024-02-26T10:47:11.220716878Z"
    }
   },
   "id": "621bdfcdd1f8fa6d",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.7150,  2.8327])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[1, 2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:45:13.248490672Z",
     "start_time": "2024-02-26T10:45:13.237983434Z"
    }
   },
   "id": "28e150d45f69a2a2",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's initialize weights of the hidden layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c0578424fb8cd99"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:14:59.512469461Z",
     "start_time": "2024-02-26T12:14:59.465792307Z"
    }
   },
   "id": "b900ffc6e912c835",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's multiply the weight with a 2 dimensional representation of input layer.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fddcdc21ba3f850b"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b8ce5344d227bf5a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 100])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_no_activation = emb.view(-1, 6) @ W1 + b1 \n",
    "h_no_activation.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:19:48.649948188Z",
     "start_time": "2024-02-26T12:19:48.641828209Z"
    }
   },
   "id": "497dd4fea27265b2",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.6017, -3.5166,  0.0954,  ...,  0.6654,  0.1866, -0.5502],\n        [ 0.9613, -1.4713,  0.4734,  ...,  1.2299, -1.2621, -1.1406],\n        [ 3.1213,  3.2348,  1.0119,  ...,  1.4983, -3.4846, -1.2529],\n        ...,\n        [-1.5172, -3.7798,  0.2104,  ..., -2.8301,  1.5355, -1.7390],\n        [ 2.3055, -6.3487,  2.7768,  ..., -2.5099, -0.0297, -4.2553],\n        [ 6.8435, -4.0417,  2.1428,  ...,  0.6571, -0.1208, -1.3713]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_no_activation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:19:52.322341893Z",
     "start_time": "2024-02-26T12:19:52.314010634Z"
    }
   },
   "id": "6dc1b3fab58fbe14",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we apply the activation function tanh"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a2d96264dcd8527"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.5382, -0.9982,  0.0951,  ...,  0.5819,  0.1845, -0.5006],\n        [ 0.7449, -0.8998,  0.4409,  ...,  0.8426, -0.8516, -0.8146],\n        [ 0.9961,  0.9969,  0.7666,  ...,  0.9048, -0.9981, -0.8491],\n        ...,\n        [-0.9082, -0.9990,  0.2074,  ..., -0.9931,  0.9114, -0.9401],\n        [ 0.9803, -1.0000,  0.9923,  ..., -0.9869, -0.0297, -0.9996],\n        [ 1.0000, -0.9994,  0.9728,  ...,  0.5765, -0.1202, -0.8790]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(h_no_activation)\n",
    "h"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:20:30.580397613Z",
     "start_time": "2024-02-26T12:20:30.571824906Z"
    }
   },
   "id": "df5beb6294cf6301",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we define the output layer which has number of rows equal to the size of the hidden layer (100) and number of columns equal to the number of characters in the dataset (27)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a874a5664eeb52a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:24:40.464664302Z",
     "start_time": "2024-02-26T12:24:40.458305838Z"
    }
   },
   "id": "552468f309e6a43f",
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we calculate the logits by multiplying the outputs of the hidden layer with the output layer.\n",
    "\n",
    "We can see that the shape aligns with rows (n observations) and columns (output units)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7f02e8f233e5dd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 27])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = h @ W2 + b2\n",
    "logits.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:24:48.841699751Z",
     "start_time": "2024-02-26T12:24:48.835756013Z"
    }
   },
   "id": "e055e70cfcc6cd51",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 27])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp()\n",
    "counts.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:34:01.624339362Z",
     "start_time": "2024-02-26T12:34:01.583030705Z"
    }
   },
   "id": "e4bc7a4b370e1a0",
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "source": [
    "We apply Softmax"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "573152a789350de5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 27])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = counts / counts.sum(dim=1, keepdim=True)\n",
    "prob.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:29:11.770979079Z",
     "start_time": "2024-02-26T12:29:11.767187753Z"
    }
   },
   "id": "f007a1542bfac713",
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we find the output probability for the correct word"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d823394eb76c08"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = prob[torch.arange(32), Y]\n",
    "probs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:32:25.991797127Z",
     "start_time": "2024-02-26T12:32:25.986448153Z"
    }
   },
   "id": "444a27c8acba326",
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the loss function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a73aae26a4e12682"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(18.9005)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -probs.log().mean()\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:32:52.164115833Z",
     "start_time": "2024-02-26T12:32:52.123243828Z"
    }
   },
   "id": "37aebb1e02d886cc",
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is actually equivalent to using the cross entropy loss in pytorch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e0f8ff974c3274d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(18.9005)"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:44:26.984147794Z",
     "start_time": "2024-02-26T12:44:26.941407094Z"
    }
   },
   "id": "d068e59d5e70f575",
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "source": [
    "Summarizing the parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b66230b52b0b9d6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parameters = [C, W1, b1, W2, b2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:38:30.018697530Z",
     "start_time": "2024-02-26T12:38:30.013575149Z"
    }
   },
   "id": "8e58153e20fbcbf8",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "600\n",
      "100\n",
      "2700\n",
      "27\n",
      "sum of parameters: 3481\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for p in parameters:\n",
    "    print(p.nelement())\n",
    "    s += p.nelement()\n",
    "    \n",
    "print(f'sum of parameters: {s}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:45:48.486531850Z",
     "start_time": "2024-02-26T12:45:48.482614705Z"
    }
   },
   "id": "1f4d63bd547a3370",
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Back Propagation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e50a258e76afe91"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T13:38:16.107999523Z",
     "start_time": "2024-02-26T13:38:16.066002730Z"
    }
   },
   "id": "166e0976977d975b",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2547752559185028\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None    \n",
    "    loss.backward()\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "    \n",
    "print(loss.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T13:40:50.975029337Z",
     "start_time": "2024-02-26T13:40:48.616395198Z"
    }
   },
   "id": "492d11134d3760d8",
   "execution_count": 65
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
